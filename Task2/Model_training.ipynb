{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb644246-2fbb-4107-9dcb-d8c4a360b75b",
   "metadata": {},
   "source": [
    "## Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27770362-7d89-46ae-a2d8-074078ec9c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spy/miniforge3/envs/assignment/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import configparser\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import T5ForConditionalGeneration, T5TokenizerFast, get_scheduler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb195402-7a43-4099-8eed-b44d00a9fad0",
   "metadata": {},
   "source": [
    "### Paths loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c76fd8f-d46a-4a7b-9cc7-8c9bb3c6f944",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "prepared_dataset_path = config['PATHS']['prepared_dataset_path']\n",
    "base_model_path = config['PATHS']['prepared_dataset_path']\n",
    "trained_model_path = config['PATHS']['prepared_dataset_path']\n",
    "model_dir = config['PATHS']['model_dir']\n",
    "\n",
    "train_tokens_path = config['PATHS']['train_tokens_path']\n",
    "val_tokens_path = config['PATHS']['val_tokens_path']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a646d7d7-c749-40fb-a3de-20b3c7f0b185",
   "metadata": {},
   "source": [
    "## Data loading\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68865a8a-3da9-4486-a1e2-850a76af7380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_text</th>\n",
       "      <th>target_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 1/2 lbs cube steaks, 1/4 cup self rising flo...</td>\n",
       "      <td>dredge steak pieces in flour. in a large skill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 medium leek, (white portion only), halved an...</td>\n",
       "      <td>in a large saucepan, saute leek in butter unti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1 whole chicken, 2 c. cream of chicken soup, s...</td>\n",
       "      <td>boil and bone chicken. mix chicken with soup, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1 crab (about 1 1/2 - 2 pounds), 2 inches ging...</td>\n",
       "      <td>mix the sauce and set aside.  clean the crab a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2 1/2 cups flour, all-purpose, 1 1/2 teaspoons...</td>\n",
       "      <td>preheat oven to 375f (190c) (190c). grease bak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          input_text  \\\n",
       "0  1 1/2 lbs cube steaks, 1/4 cup self rising flo...   \n",
       "1  1 medium leek, (white portion only), halved an...   \n",
       "2  1 whole chicken, 2 c. cream of chicken soup, s...   \n",
       "3  1 crab (about 1 1/2 - 2 pounds), 2 inches ging...   \n",
       "4  2 1/2 cups flour, all-purpose, 1 1/2 teaspoons...   \n",
       "\n",
       "                                         target_text  \n",
       "0  dredge steak pieces in flour. in a large skill...  \n",
       "1  in a large saucepan, saute leek in butter unti...  \n",
       "2  boil and bone chicken. mix chicken with soup, ...  \n",
       "3  mix the sauce and set aside.  clean the crab a...  \n",
       "4  preheat oven to 375f (190c) (190c). grease bak...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(prepared_dataset_path)\n",
    "df.dropna(how='any', inplace=True)\n",
    "df.isna().sum()\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4078da10-0c47-49f5-a395-d3665851008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_val = train_test_split(df, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c2e5ace-4885-475d-bd13-261bf09779b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9000, 2), (1000, 2))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del df\n",
    "df_train.shape, df_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b16d2ed-1afa-4d8b-82f0-b68ef84a21d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 1/1 [00:05<00:00,  5.75s/it]\n",
      "100%|█████████████████████████████████████████████| 1/1 [00:00<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = T5TokenizerFast.from_pretrained(model_dir)\n",
    "\n",
    "batch_size = 100000\n",
    "\n",
    "def preprocess_in_batches(df, batch_size=512):\n",
    "    input_ids, attention_masks, labels = [], [], []\n",
    "\n",
    "    for i in tqdm(range(0, len(df), batch_size)):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "\n",
    "        # Tokenize inputs\n",
    "        inputs = tokenizer(\n",
    "            batch_df[\"input_text\"].tolist(),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        # Tokenize targets\n",
    "        targets = tokenizer(\n",
    "            batch_df[\"target_text\"].tolist(),\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "        input_ids.append(inputs[\"input_ids\"])\n",
    "        attention_masks.append(inputs[\"attention_mask\"])\n",
    "        labels.append(targets[\"input_ids\"])\n",
    "\n",
    "        # Optionally free memory\n",
    "        del inputs, targets\n",
    "\n",
    "    # Concatenate all batches into single tensors\n",
    "    return {\n",
    "        \"input_ids\": torch.cat(input_ids, dim=0),\n",
    "        \"attention_mask\": torch.cat(attention_masks, dim=0),\n",
    "        \"labels\": torch.cat(labels, dim=0)\n",
    "    }\n",
    "\n",
    "# Use smaller batches if memory is tight\n",
    "train_data = preprocess_in_batches(df_train, batch_size=batch_size)\n",
    "del df_train\n",
    "\n",
    "val_data = preprocess_in_batches(df_val, batch_size=batch_size)\n",
    "del df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a028b804-872b-49ed-aab8-65c5bc6f84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Saving token because it is costly to run multiple time\n",
    "\n",
    "torch.save(train_data, train_tokens_path)\n",
    "torch.save(val_data, val_tokens_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fd2b80c-0de2-40dc-85a0-b31e5673d7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Saving token because it is costly to run multiple time\n",
    "\n",
    "train_data = torch.load(train_tokens_path)\n",
    "val_data = torch.load(val_tokens_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5dc30acf-05eb-4152-9c4e-b5061a56a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "num_epochs = 3\n",
    "lr = 5e-5\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    list(zip(train_data[\"input_ids\"], train_data[\"attention_mask\"], train_data[\"labels\"])),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    list(zip(val_data[\"input_ids\"], val_data[\"attention_mask\"], val_data[\"labels\"])),\n",
    "    batch_size=batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ec45bc1-e2c9-49fe-85f8-fc51116dfeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7ad29-5794-48a0-9793-371231e2efe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4262df46-da9f-4b3e-9e9c-f96fa071d7ca",
   "metadata": {},
   "source": [
    "### Model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac34cf26-05e2-44c9-83f1-5d582f813e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The module name  (originally ) is not a valid Python identifier. Please rename the original module to avoid import issues.\n"
     ]
    }
   ],
   "source": [
    "# Load the model safely\n",
    "model = T5ForConditionalGeneration.from_pretrained(\n",
    "    model_dir,\n",
    "    dtype='auto',\n",
    "    device_map=\"auto\"            # automatically put on GPU if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f79f60b-0eeb-42ec-b1c7-cb51310dd61e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded on device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = next(model.parameters()).device\n",
    "print(\"Model loaded on device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a1e0154-f1b1-46cd-b405-4e912869393d",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=lr)\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1228b16-c0ac-4214-8e7a-9d27c8821793",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e8dfebb-57e8-4880-9e1e-12091cda89a4",
   "metadata": {},
   "source": [
    "### Evaluating model performance before finetunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cdf4d6d-adcc-475b-82ff-5e4913e63780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating initial loss: 100%|████████████████| 250/250 [04:25<00:00,  1.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average loss before fine-tuning: 23.5920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # no gradient updates\n",
    "val_loss = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(val_loader, desc=\"Evaluating initial loss\"):\n",
    "        input_ids, attention_mask, labels = batch  # unpack the tuple\n",
    "        input_ids = input_ids.to(device)\n",
    "        attention_mask = attention_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )        \n",
    "        total_loss += outputs.loss.item()\n",
    "\n",
    "        # generated_ids = model.generate(\n",
    "        #     input_ids=input_ids,\n",
    "        #     attention_mask=attention_mask,\n",
    "        #     max_length=labels.shape[1],\n",
    "        #     num_beams=4\n",
    "        # )\n",
    "\n",
    "        # preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "        # refs = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "        # all_preds.extend(preds)\n",
    "        # all_labels.extend(refs)\n",
    "\n",
    "initial_loss = total_loss / len(val_loader)\n",
    "print(f\"Average loss before fine-tuning: {initial_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fae98-4341-461d-a1fb-5f320ecfeb80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75dcd1a2-834b-44ce-9fba-b8f5a2d57c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
